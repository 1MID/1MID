# 股票交易爬蟲專案筆記

[輸出範本](./DailyAnalysisReport_2024_07_04.xlsx)

## **專案背景與動機**

### **為什麼要做這個？網路不都查的到資料嗎？**
雖然網路上有許多股票資料可以查詢，但這些平台的查詢條件通常受到限制。例如：
- 無法篩選出偏持倉或偏當沖的分行。
- 無法根據自定義規則產生報表。

透過建立自己的資料庫，可以使用 SQL 查詢來實現更靈活的數據分析，例如：
- 計算每個分行當天交易的每筆明細。
- 根據特定交易條件自動生成報表。

### **希望實現的功能**
- 追蹤特定券商，觀察特殊情境（如分行操作不一致）。
- 分析特定券商在特定價格範圍內的偏多或偏空操作。
- 自動處理數據並生成 Excel 報表，快速檢視值得注意的交易。

---

## **專案執行細節**

### **開發時間**
- 約 4 個工作天。

### **專案優勢**
- 興趣驅動，挑戰自我。
- 具備前端基礎，快速解決爬蟲開發中的問題。
- 熱衷於思考並享受解決問題的過程。

### **執行效率**
- 爬取 150 支股票耗時：33:51.494 (m:ss.mmm)。
- 寫入資料：455,393 筆（約 122 MB）。

---

## **技術架構與實現**

### **架構**
[DB Schema](./schema/schema.md)

### **技術棧**
- **後端**：Node.js
- **資料庫**：MySQL

### **資料庫設計**
1. 每個 Table 設計有關鍵值（如券商編號、日期），方便執行複雜查詢。
2. 增加自增鍵與寫入時間戳，便於後續追蹤。
3. 資料儲存於外接硬碟（2TB），避免占用筆電資源並提升安全性。

### **功能簡述**
提供完整流程：
1. 爬取股票交易資料並生成 CSV 檔案。
2. 解析 CSV 並進行運算處理。
3. 將處理後的數據寫入各個 Table。
4. 完成後自動備份 CSV 至外接硬碟。

---

## **優化與挑戰**

### **效能優化**
1. **批次寫入**：
   - 初始設計每次僅插入一筆資料，導致處理時間過長（單支股票需約 20 分鐘）。
   - 改為每次批量插入 2000 筆，大幅提升速度，同時避免線程阻塞。

2. **程式重構**：
   - 將無關聯的 Promise function 改為併行執行，減少執行時間。
   - 確保爬蟲啟用後僅建立一次 DB 連線，避免重複連線浪費資源。

3. **索引設置**：
   - 為資料庫增加索引以加速查詢，但需平衡寫入性能與儲存空間消耗。

### **模組化設計**
1. 將功能模組化，重複使用代碼（如檔案處理模組）。
2. 遵循 Clean Code 原則，保持程式碼可讀性、一致性與單一職責。

### **異常處理**
1. 每個 Promise 均設有 `catch` 機制，自動 Retry 錯誤部分。
2. 錯誤記錄於 Table，方便快速定位問題並排除。
3. 即使部分爬蟲失敗，也不影響其他股票執行。

---

## **面臨的挑戰**

### **爬蟲相關**
1. **動態網站處理**：
   - 網頁需等待 JS 完成渲染才能抓取數據。採用 pause 與元素檢查機制確保穩定性。
2. **frame 結構**：
   - 網頁結構複雜，查找文檔及技術論壇資訊以解決抓取問題。
3. **驗證碼**：
   - 初期嘗試透過呼叫破解驗證碼失敗，但最終找到替代方案成功解決。

### **資料增長導致性能下降**
1. 執行初期需約 33 分鐘，但兩週後增至 47 分鐘。
2. 採用索引優化查詢性能，但需權衡寫入成本與儲存空間消耗。

---

## **優點**

1. 效能優化與批次處理設計顯著提升速度。
2. 模組化設計與清晰註解確保程式易於維護與擴展。
3. 完善的異常處理機制提升系統穩定性與可用性。
4. 實現從爬取、解析到報表生成的一條龍流程，展示全面技術能力。

---

## 結語

在這個專案中，我從零開始規劃了整個資料庫架構，並設計了爬蟲系統與資料處理流程，實現了一套完整的股票交易數據分析解決方案。此專案不僅展示了我對技術的熱情，也體現了以下幾個關鍵能力：

1. **資料庫規劃與優化**：
   - 從資料庫設計到索引優化，處理大規模數據（如每日新增數十萬筆交易資料）
   - 透過模組化設計，為未來的功能擴展與維護提供便利。

2. **爬蟲開發與問題解決**：
   - 成功應對動態網站、驗證碼等技術挑戰，並設計穩定可靠的爬蟲流程。
   - 結合資料解析與自動化報表生成，實現了一條龍式的數據處理。

3. **效能優化與穩定性提升**：
   - 透過批次寫入、程式重構及異常處理機制，大幅提升系統效率與穩定性。
   - 即使面對龐大數據量，系統仍能保持高效運行。

4. **技術興趣與執行力**：
   - 此專案完全由個人獨立完成，展現了我對技術的熱愛及解決問題的執行力。
   - 在短時間內完成從需求分析到實際落地的全流程開發。

這個專案體現了自己在資料庫設計、SQL查詢、爬蟲開發、效能優化及問題解決方面的能力。


---